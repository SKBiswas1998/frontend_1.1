{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31a9e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pymupdf pytesseract faiss-cpu sentence-transformers transformers nltk google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3045dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import faiss\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a35fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download NLTK punkt tokenizer (only once needed)\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684027c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and chunk PDF\n",
    "\n",
    "def load_pdf(file_path: str, chunk_size: int = 1000, lang: str = 'eng+ben') -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Loads PDF (digital or scanned), extracts text (with OCR if needed), and returns sentence-based chunks.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF.\n",
    "        chunk_size (int): Approx. number of words per chunk.\n",
    "        lang (str): OCR language for pytesseract.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: List of text chunks with metadata.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        page_text = page.get_text()\n",
    "\n",
    "        if len(page_text.strip()) < 20:\n",
    "            pix = page.get_pixmap(dpi=300)\n",
    "            img = Image.open(io.BytesIO(pix.tobytes()))\n",
    "            page_text = pytesseract.image_to_string(img, lang=lang)\n",
    "\n",
    "        sentences = sent_tokenize(page_text)\n",
    "\n",
    "        current_chunk = []\n",
    "        word_count = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            word_count += len(words)\n",
    "            current_chunk.append(sentence)\n",
    "\n",
    "            if word_count >= chunk_size:\n",
    "                chunks.append({\n",
    "                    'id': chunk_id,\n",
    "                    'text': ' '.join(current_chunk),\n",
    "                    'page': page_num\n",
    "                })\n",
    "                chunk_id += 1\n",
    "                current_chunk = []\n",
    "                word_count = 0\n",
    "\n",
    "        # Add any remaining sentences\n",
    "        if current_chunk:\n",
    "            chunks.append({\n",
    "                'id': chunk_id,\n",
    "                'text': ' '.join(current_chunk),\n",
    "                'page': page_num\n",
    "            })\n",
    "            chunk_id += 1\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99966489",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load and chunk a PDF\n",
    "pdf_path = '/kaggle/input/ssc-math-pdf/Higher Math 9-10 Com Opt.pdf'\n",
    "chunks = load_pdf(pdf_path)\n",
    "print(f\"Loaded {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b6ee8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load a stronger multilingual sentence-transformer model\n",
    "embedder = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "# Compute embeddings\n",
    "texts = [chunk['text'] for chunk in chunks]\n",
    "embeddings = embedder.encode(texts, convert_to_numpy=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17424642",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "print(f\"FAISS index loaded with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb891e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to retrieve top-k chunks\n",
    "\n",
    "def retrieve(query: str, top_k: int = 25) -> List[Dict]:\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    results = [chunks[i] for i in indices[0]]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f00d2c",
   "metadata": {},
   "source": [
    "# Configure Gemini API Key\n",
    "# Replace with your own key or use environment variable\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"AIzaSyBpnhF7gsPKKpM3qHCRQRWYRnirwLX_8PQ\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82707f9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate answer with Gemini\n",
    "\n",
    "def generate_answer(context_chunks: List[Dict], query: str, model_name=\"gemini-1.5-pro-latest\") -> str:\n",
    "    context = \"\\n\\n\".join([chunk['text'] for chunk in context_chunks])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a professional educational assistant.\n",
    "    use the given context to answer the user's question.\n",
    "\n",
    "    VERY IMPORTANT:\n",
    "    - Do not hallucinate.\n",
    "    - If the topic is NOT found in the context, reply: \"Not enough information in the book.\"\n",
    "    - Do NOT use LaTeX.\n",
    "    - Answer clearly and in normal text format.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b5bc7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"explain trigonometric identity with a solved problem\"\n",
    "retrieved_context = retrieve(query)\n",
    "long_answer = generate_answer(retrieved_context, query)\n",
    "print(\"\\nGenerated Answer:\\n\")\n",
    "print(long_answer)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
